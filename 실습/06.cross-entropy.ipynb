{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06.cross-entropy.ipynb","provenance":[],"collapsed_sections":["ZMJgI4nlRhpc","QsY3i2TD0sX4","3MzQCX-C_Yt0","R4YUpKlk33sK","lH9GJO4Y7IKQ","cZWOp0aKf_R1","nMLEus7nI1lj"],"authorship_tag":"ABX9TyP8zmMQHWOsAuIapbgpFKVu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZMJgI4nlRhpc"},"source":["# Env"]},{"cell_type":"code","metadata":{"id":"VntzlNra09ud"},"source":["# imports\n","import argparse\n","import os\n","import random\n","import shutil\n","import json\n","import zipfile\n","import math\n","import copy\n","import collections\n","import re\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","# import sentencepiece as spm\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","from tqdm.notebook import tqdm, trange"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sXgZx8L8Rhpd"},"source":["# 환경 설정\n","args = {\n","    # random seed value\n","    \"seed\": 1234,\n","}\n","args = argparse.Namespace(**args)\n","\n","print(args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vo0a3gCSRhpe"},"source":["# random seed 설정\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QsY3i2TD0sX4"},"source":["# Entropy"]},{"cell_type":"code","metadata":{"id":"dLRvkP2_0Q9M"},"source":["# Generate linearly spaced vector\n","p = np.linspace(0, 1, 101)[1:-1]\n","q = 1 - p\n","prob = np.stack([p, q], axis=-1)\n","\n","print(prob)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MrzRg-VF06cB"},"source":["# entropy\n","entropy = - prob * np.log2(prob)\n","entropy = np.sum(entropy, axis=-1)\n","entropy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZLSvMcpN0_TR"},"source":["# draw plot\n","plt.plot(p, entropy)\n","plt.title('Entropy')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3MzQCX-C_Yt0"},"source":["# Cross Entropy"]},{"cell_type":"code","metadata":{"id":"m8_e5x992elf"},"source":["# Generate linearly spaced vector\n","p = np.linspace(0, 1, 11)[1:-1]\n","q = p\n","print(p, q)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gr_dp1I-NYg"},"source":["cross_entropy = np.zeros((9, 9))\n","for i, p_a in enumerate(p):\n","    p_b = 1 - p_a\n","    for j, q_a in enumerate(q):\n","        q_b = 1 - q_a\n","        ce = -(p_a * np.log(q_a) + p_b * np.log(q_b))\n","        cross_entropy[i][j] = np.round(ce, 2)\n","\n","print(cross_entropy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R4YUpKlk33sK"},"source":["# Corss Entropy Loss"]},{"cell_type":"code","metadata":{"id":"-d2Erpgl33Qi"},"source":["y_true = [[1, 0, 0, 0]] * 4 + [[0, 1, 0, 0]] * 3 + [[0, 0, 1, 0]] * 2 + [[0, 0, 0, 1]] * 1\n","y_true = np.array(y_true)\n","y_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ti9Z9TBc-m8i"},"source":["y_pred = [[0.25, 0.25, 0.25, 0.25]] * 10\n","y_pred = np.array(y_pred)\n","y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AQEuKopL9T43"},"source":["$-\\log \\hat{y}_{ij}$ 값"]},{"cell_type":"code","metadata":{"id":"hYJuPYlOTPDY"},"source":["y_log_pred = -np.log(y_pred)\n","y_log_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HaJaR0qY9ivB"},"source":["$-y_{ij} \\log \\hat{y}_{ij}$ 값"]},{"cell_type":"code","metadata":{"id":"EiMq6dq5Tc7_"},"source":["ce_item = y_true * y_log_pred\n","ce_item"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9YMcjeuAAE8"},"source":["$-\\sum_{j=1}^C y_{ij} \\ \\log \\hat{y}_{ij}$ 값"]},{"cell_type":"code","metadata":{"id":"KFE0Yg7dTv1y"},"source":["ces = np.sum(ce_item, axis=-1)\n","ces"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_oVxt51jAKxH"},"source":["$-{1 \\over N} \\sum_{i=n}^N\\sum_{j=1}^C y_{ij} \\ \\log \\hat{y}_{ij}$"]},{"cell_type":"code","metadata":{"id":"6ywwjhAE9yIM"},"source":["loss = np.mean(ces)\n","loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYMPCsG492vc"},"source":["y_pred = [[0.40, 0.30, 0.20, 0.10]] * 10\n","y_pred = np.array(y_pred)\n","y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EzoFSaj_ATxz"},"source":["$-\\log \\hat{y}_{ij}$ 값"]},{"cell_type":"code","metadata":{"id":"SqE9CxSAATxz"},"source":["y_log_pred = -np.log(y_pred)\n","y_log_pred"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"opiBLuCMATx9"},"source":["$-y_{ij} \\log \\hat{y}_{ij}$ 값"]},{"cell_type":"code","metadata":{"id":"TQzo1KisATx9"},"source":["ce_item = y_true * y_log_pred\n","ce_item"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zQTynfPATx9"},"source":["$-\\sum_{j=1}^C y_{ij} \\ \\log \\hat{y}_{ij}$ 값"]},{"cell_type":"code","metadata":{"id":"X5w1B0RHATx9"},"source":["ces = np.sum(ce_item, axis=-1)\n","ces"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ho0cTdrTATx-"},"source":["$-{1 \\over N} \\sum_{i=n}^N\\sum_{j=1}^C y_{ij} \\ \\log \\hat{y}_{ij}$"]},{"cell_type":"code","metadata":{"id":"PCxjwbfFATx-"},"source":["loss = np.mean(ces)\n","loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lH9GJO4Y7IKQ"},"source":["# 실습\n","- 10개 짜리 두개의 확률분포 y_true, y_pred를 선언하고 두 확률분포의 cross-entropy loss를 직접 계산하세요."]},{"cell_type":"markdown","metadata":{"id":"cZWOp0aKf_R1"},"source":["# TF Cross Entropy"]},{"cell_type":"code","metadata":{"id":"n6i4Yr-bG7hC"},"source":["y_true = np.random.randint(0, 4, (10,))\n","y_true"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z1wXOz-UGjir"},"source":["y_prob = np.zeros((10, 4))\n","y_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GC1coit6IQz1"},"source":["for i, y in enumerate(y_true):\n","    y_prob[i, y] = 1\n","y_prob"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WivOUN_sGv75"},"source":["logits = np.random.randn(10, 4)\n","logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpTmtKNrG1ds"},"source":["y_pred = tf.nn.softmax(logits)\n","y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"89bfPsfGMgUi"},"source":["ce1 = -y_prob * np.log(y_pred)\n","ce1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0EB259ePMpRZ"},"source":["ce2 = np.sum(ce1, axis=-1)\n","ce2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KM9YfBEuMwWu"},"source":["ce = np.mean(ce2)\n","ce"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PhbRInjKdjT2"},"source":["tf.keras.losses.CategoricalCrossentropy()(y_prob, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDjK3ChefllH"},"source":["tf.keras.losses.CategoricalCrossentropy(from_logits=True)(y_prob, logits)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZT5h92rUgIll"},"source":["tf.keras.losses.SparseCategoricalCrossentropy()(y_true, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Npk_SaQfgQRF"},"source":["tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(y_true, logits)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMLEus7nI1lj"},"source":["# 실습\n","- 긍정, 부정 두가지를 예측하는 10개의 sample의 정답 y_true와 logits을 선언하고 아래 형식에 따른 cross entropy loss를 구하세요.\n","  - 직접계산\n","  - tf.keras.losses.CategoricalCrossentropy()\n","  - tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n","  - tf.keras.losses.SparseCategoricalCrossentropy()\n","  - tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"]}]}