{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"24.02.transformer-chat.ipynb","provenance":[],"collapsed_sections":["JHkHg6XAXoyK","0TyJlt-k7yzW","1toqkZBj4iqG","097BJVHG_QfR","WB0cfrHoGOKX","auGUODYIiSxK","w_ch3BI9EC05","Xv8wb2wgEC05","q9TJovagEC08","j3pUWwz0EC0_","hMoKqFvLEC1A","x83Kl8yPEC1B","MWob-9sOEC1E"],"authorship_tag":"ABX9TyNFaekwXm5sTEaJEM4BHrhs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JHkHg6XAXoyK"},"source":["# Evn*"]},{"cell_type":"code","metadata":{"id":"WkYXFwcBXJDG","executionInfo":{"status":"ok","timestamp":1647860272259,"user_tz":-540,"elapsed":5437,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingwsOzB_fFlwKa3Z4CH1TlVnyWMq-xfwt25iMhS0=s64","userId":"02662570985009482782"}}},"source":["# imports\n","import argparse\n","import os\n","import random\n","import shutil\n","import json\n","import zipfile\n","import math\n","import copy\n","import collections\n","import re\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import sentencepiece as spm\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","\n","from tqdm.notebook import tqdm, trange"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"BF-NLGZTGvTR"},"source":["# 환경 설정\n","args = {\n","    # random seed value\n","    \"seed\": 1234\n","}\n","args = argparse.Namespace(**args)\n","\n","print(args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvjyruUlXtlR"},"source":["# random seed 설정\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BC3fXkhdYcYt"},"source":["# gpu 사용량 확인\n","!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"byCIiLJBbFHh"},"source":["# data dir\n","data_dir = '/content/drive/MyDrive/Data/nlp'\n","os.listdir(data_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_uejAndANVD"},"source":["sychat_dir = os.path.join(data_dir, \"songys-chat\")\n","if not os.path.isdir(sychat_dir):\n","    os.makedirs(sychat_dir)\n","os.listdir(sychat_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0TyJlt-k7yzW"},"source":["# Vocabulary*"]},{"cell_type":"code","metadata":{"id":"har00GjJ71ZH"},"source":["# vocab loading\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(os.path.join(data_dir, 'kowiki', 'kowiki_32000.model'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1toqkZBj4iqG"},"source":["# Transformer"]},{"cell_type":"code","metadata":{"id":"g3vPIEAW4g3Q"},"source":["args.d_model = 256  # d_model: model hidden dim\n","args.n_head = 4  # n_head: multi head attention head number\n","args.d_head = 64  # d_head: multi head attention head dim\n","args.dropout = 0.1  # dropout: dropout rate\n","args.d_ff = 1024  # d_ff: feed forward dim\n","args.norm_eps = 1e-9  # norm_eps: layernormal epsilon\n","args.n_layer = 3  # n_layer: layer number\n","args.n_seq = 128  # n_seq: sequence max number\n","args.n_vocab = len(vocab)  # n_vocab: vocab count\n","args.i_pad = vocab.pad_id()  # i_pad: vocab pad id\n","\n","args"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j5cEzVnUdZeY"},"source":["def get_pad_mask(tokens, i_pad=0):\n","    \"\"\"\n","    pad mask 계산하는 함수\n","    :param tokens: tokens (bs, n_seq)\n","    :param i_pad: id of pad\n","    :return mask: pad mask (pad: 1, other: 0)\n","    \"\"\"\n","    # pad: True, others: False\n","    mask = tf.math.equal(tokens, i_pad)\n","    # boolean -> float 32\n","    mask = tf.cast(mask, tf.float32)\n","    # expand dimension for Q n_seq\n","    mask = tf.expand_dims(mask, axis=1)\n","    return mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"arxRhssHdeL_"},"source":["def get_causal_mask(tokens, i_pad=0):\n","    \"\"\"\n","    causal mask 계산하는 함수\n","    :param tokens: tokens (bs, n_seq)\n","    :param i_pad: id of pad\n","    :return mask: causal and pad mask (causal or pad: 1, other: 0)\n","    \"\"\"\n","    # n_seq 조회\n","    n_seq = tf.shape(tokens)[1]\n","    # all one mask\n","    mask = tf.ones((n_seq, n_seq))\n","    # make reverse causal mask\n","    mask = tf.linalg.band_part(mask, -1, 0)\n","    # 0 -> 1, 1 -> 0\n","    mask = 1 - mask\n","    # expand dim for bs\n","    mask = tf.expand_dims(mask, axis=0)\n","    # get pad_mask\n","    pad_mask = get_pad_mask(tokens, i_pad)\n","    # mask all causal_mask or pad_mask\n","    mask = tf.maximum(mask, pad_mask)\n","    return mask"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w6WHOHHNdeHp"},"source":["class ScaleDotProductAttention(tf.keras.layers.Layer):\n","    \"\"\"\n","    Scale Dot Product Attention Class\n","    \"\"\"\n","    def __init__(self, name=\"scale_dot_product_attention\"):\n","        \"\"\"\n","        생성자\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: Q, K, V, attn_mask tuple\n","        :return attn_out: attention 실행 결과\n","        \"\"\"\n","        Q, K, V, attn_mask = inputs\n","        # matmul Q, K.T\n","        attn_score = tf.matmul(Q, K, transpose_b=True)\n","        # d_k\n","        d_k = tf.cast(tf.shape(K)[-1], tf.float32)\n","        # scale = d_k ** 0.5\n","        scale = tf.math.sqrt(d_k)\n","        # divide by scale\n","        attn_scale = tf.math.divide(attn_score, scale)\n","        # do mask (subtract 1e-9 for masked value)\n","        attn_scale -= 1.e9 * attn_mask\n","        # calculate attention prob\n","        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n","        # weighted sum of V\n","        attn_out = tf.matmul(attn_prob, V)\n","        return attn_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xo6k1OANdeDt"},"source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","    \"\"\"\n","    Multi Head Attention Class\n","    \"\"\"\n","    def __init__(self, args, name=\"multi_head_attention\"):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","        self.d_model = args.d_model\n","        self.n_head = args.n_head\n","        self.d_head = args.d_head\n","\n","        # Q, K, V input dense layer\n","        self.W_Q = tf.keras.layers.Dense(self.n_head * self.d_head)\n","        self.W_K = tf.keras.layers.Dense(self.n_head * self.d_head)\n","        self.W_V = tf.keras.layers.Dense(self.n_head * self.d_head)\n","        # Scale Dot Product Attention class\n","        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n","        # output dense layer\n","        self.W_O = tf.keras.layers.Dense(self.d_model)\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: Q, K, V, attn_mask tuple\n","        :return attn_out: attention 실행 결과\n","        \"\"\"\n","        Q, K, V, attn_mask = inputs\n","        # build multihead Q, K, V\n","        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [-1, tf.shape(Q)[1], self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n","        K_m = tf.transpose(tf.reshape(self.W_K(K), [-1, tf.shape(K)[1], self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n","        V_m = tf.transpose(tf.reshape(self.W_V(V), [-1, tf.shape(V)[1], self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n","        # build multihead mask\n","        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n","        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n","        attn_out_m = self.attention((Q_m, K_m, V_m, attn_mask_m))  # (bs, n_head, Q_len, d_head)\n","        # transpose\n","        attn_out_t = tf.transpose(attn_out_m, perm=[0, 2, 1, 3])   # (bs, n_head, Q_len, d_head) -> (bs, Q_len, n_head, d_head)\n","        # reshape\n","        attn_out_c = tf.reshape(attn_out_t, [-1, tf.shape(Q)[1], self.n_head * self.d_head])  # (bs, Q_len, n_head, d_head) -> (bs, Q_len, n_head * d_head)\n","        # linear for output\n","        attn_out = self.W_O(attn_out_c) # (bs, Q_len, n_head * d_head) -> (bs, Q_len, d_model)\n","        return attn_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5QYqafRdd_Y"},"source":["class PositionWiseFeedForward(tf.keras.layers.Layer):\n","    \"\"\"\n","    Position Wise Feed Forward Class\n","    \"\"\"\n","    def __init__(self, args, name=\"feed_forward\"):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","        self.W_1 = tf.keras.layers.Dense(args.d_ff, activation=tf.nn.relu)\n","        self.W_2 = tf.keras.layers.Dense(args.d_model)\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: inputs\n","        :return ff_val: feed forward 실행 결과\n","        \"\"\"\n","        # linear W_1 and W_2\n","        ff_val = self.W_1(inputs)\n","        ff_val = self.W_2(ff_val)\n","        return ff_val"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ai50zAahdd9P"},"source":["class EncoderLayer(tf.keras.layers.Layer):\n","    \"\"\"\n","    Encoder Layer Class\n","    \"\"\"\n","    def __init__(self, args, name='encoder_layer'):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","        self.self_attention = MultiHeadAttention(args)\n","        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=args.norm_eps)\n","\n","        self.ffn = PositionWiseFeedForward(args)\n","        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=args.norm_eps)\n","\n","        self.dropout = tf.keras.layers.Dropout(args.dropout)\n"," \n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: enc_hidden, self_mask tuple\n","        :return enc_out: EncoderLayer 실행 결과\n","        \"\"\"\n","        enc_hidden, self_mask = inputs\n","        # self attention\n","        self_attn_val = self.self_attention((enc_hidden, enc_hidden, enc_hidden, self_mask))\n","        # add and layer normal\n","        norm1_val = self.norm1(enc_hidden + self.dropout(self_attn_val))\n","        \n","        # feed forward\n","        ffn_val = self.ffn(norm1_val)\n","        # add and layer normal\n","        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n","\n","        return enc_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SOp436lXdd4p"},"source":["class DecoderLayer(tf.keras.layers.Layer):\n","    \"\"\"\n","    Decoder Layer Class\n","    \"\"\"\n","    def __init__(self, args, name='decoder_layer'):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","        self.self_attention = MultiHeadAttention(args)\n","        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=args.norm_eps)\n","\n","        self.ende_attn = MultiHeadAttention(args)\n","        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=args.norm_eps)\n","\n","        self.ffn = PositionWiseFeedForward(args)\n","        self.norm3 = tf.keras.layers.LayerNormalization(epsilon=args.norm_eps)\n","\n","        self.dropout = tf.keras.layers.Dropout(args.dropout)\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: dec_hidden, enc_out, self_mask, ende_mask tuple\n","        :return dec_out: DecoderLayer 실행 결과\n","        \"\"\"\n","        dec_hidden, enc_out, self_mask, ende_mask = inputs\n","        # self attention\n","        self_attn_val = self.self_attention((dec_hidden, dec_hidden, dec_hidden, self_mask))\n","        # add and layer normal\n","        norm1_val = self.norm1(dec_hidden + self.dropout(self_attn_val))\n","\n","        # encoder and decoder attention\n","        ende_attn_val = self.ende_attn((norm1_val, enc_out, enc_out, ende_mask))\n","        # add and layer normal\n","        norm2_val = self.norm2(norm1_val + self.dropout(ende_attn_val))\n","\n","        # feed forward\n","        ffn_val = self.ffn(norm2_val)\n","        # add and layer normal\n","        dec_out = self.norm3(norm2_val + self.dropout(ffn_val))\n","\n","        return dec_out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z4nAbHAedd1m"},"source":["class SharedEmbedding(tf.keras.layers.Layer):\n","    \"\"\"\n","    Weighed Shaed Embedding Class\n","    \"\"\"\n","    def __init__(self, args, name='weight_shared_embedding'):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","        self.n_vocab = args.n_vocab\n","        self.d_model = args.d_model\n","    \n","    def build(self, input_shape):\n","        \"\"\"\n","        shared weight 생성\n","        :param input_shape: Tensor Shape (not used)\n","        \"\"\"\n","        with tf.name_scope('shared_embedding_weight'):\n","            self.shared_weights = self.add_weight(\n","                'weights',\n","                shape=[self.n_vocab, self.d_model],\n","                initializer=tf.keras.initializers.TruncatedNormal(stddev=self.d_model ** -0.5)\n","            )\n","\n","    def call(self, inputs, mode='embedding'):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: 입력\n","        :param mode: 실행 모드\n","        :return: embedding or linear 실행 결과\n","        \"\"\"\n","        # mode가 embedding일 경우 embedding lookup 실행\n","        if mode == 'embedding':\n","            return self._embedding(inputs)\n","        # mode가 linear일 경우 linear 실행\n","        elif mode == 'linear':\n","            return self._linear(inputs)\n","        # mode가 기타일 경우 오류 발생\n","        else:\n","            raise ValueError(f'mode {mode} is not valid.')\n","    \n","    def _embedding(self, inputs):\n","        \"\"\"\n","        embedding lookup\n","        :param inputs: 입력\n","        \"\"\"\n","        # lookup by gather\n","        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n","        # muliply d_model ** 0.5\n","        embed *= self.d_model ** 0.5\n","        return embed\n","\n","    def _linear(self, inputs):  # (bs, n_seq, d_model)\n","        \"\"\"\n","        linear 실행\n","        :param inputs: 입력\n","        \"\"\"\n","        # matmul inputs, shared_weights (transpose_b=True)\n","        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sUDe_qOHddvP"},"source":["class PositionalEmbedding(tf.keras.layers.Layer):\n","    \"\"\"\n","    Positional Embedding Class\n","    \"\"\"\n","    def __init__(self, args, name='position_embedding'):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","        \n","        pos_encoding = PositionalEmbedding.get_sinusoid_encoding(args.n_seq, args.d_model)\n","        self.embedding = tf.keras.layers.Embedding(args.n_seq, args.d_model, trainable=False, weights=[pos_encoding])\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: 입력\n","        :return embed: positional embedding lookup 결과\n","        \"\"\"\n","        # make position (0...n_seq)\n","        position = tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True)\n","        position = tf.cast(position, tf.int32)\n","        # embedding lookup\n","        embed = self.embedding(position)\n","        return embed\n","\n","    @staticmethod\n","    def get_sinusoid_encoding(n_seq, d_model):\n","        \"\"\"\n","        sinusoid encoding 생성\n","        :param n_seq: sequence number\n","        :param n_seq: model hidden dimension\n","        :return: positional encoding table\n","        \"\"\"\n","        # calculate exp\n","        exs = np.array([2 * (i_ang // 2) / d_model for i_ang in range(d_model)])\n","        # calculate power\n","        angles = np.power(10000, exs)\n","        # make position\n","        pos = np.array([[i] for i in range(n_seq)])\n","        # position angle\n","        pos_encoding = pos / angles\n","        # sin even number\n","        pos_encoding[:, 0::2] = np.sin(pos_encoding[:, 0::2])\n","        # print(pos_encoding)\n","        # cos odd number\n","        pos_encoding[:, 1::2] = np.cos(pos_encoding[:, 1::2])\n","        # print(pos_encoding)\n","        return tf.cast(pos_encoding, tf.float32)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9ra5pGArddfi"},"source":["class Transformer(tf.keras.Model):\n","    \"\"\"\n","    Transformer Class\n","    \"\"\"\n","    def __init__(self, args, name='transformer'):\n","        \"\"\"\n","        생성자\n","        :param args: Args 객체\n","        :param name: layer name\n","        \"\"\"\n","        super().__init__(name=name)\n","\n","        self.i_pad = args.i_pad\n","        self.embedding = SharedEmbedding(args)\n","        self.position = PositionalEmbedding(args)\n","        \n","        self.encoder_layers = [EncoderLayer(args, name=f'encoder_layer_{i}') for i in range(args.n_layer)]\n","        self.decoder_layers = [DecoderLayer(args, name=f'decoder_layer_{i}') for i in range(args.n_layer)]\n","\n","        self.dropout = tf.keras.layers.Dropout(args.dropout)\n","\n","    def call(self, inputs):\n","        \"\"\"\n","        layer 실행\n","        :param inputs: enc_tokens, dec_tokens tuple\n","        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n","        \"\"\"\n","        enc_tokens, dec_tokens = inputs\n","        # encoder self attention mask\n","        enc_self_mask = get_pad_mask(enc_tokens, self.i_pad)\n","        # decoder self attention mask\n","        dec_self_mask = get_causal_mask(dec_tokens, self.i_pad)\n","        # encoder and decoder attention mask\n","        enc_dec_mask = get_pad_mask(enc_tokens, self.i_pad)\n","\n","        # enc_tokens, dec_tokens embedding lookup\n","        enc_hidden = self.embedding(enc_tokens) + self.position(enc_tokens)\n","        enc_hidden = self.dropout(enc_hidden)\n","\n","        # call encoder layers\n","        for encoder_layer in self.encoder_layers:\n","            enc_hidden = encoder_layer((enc_hidden, enc_self_mask))\n","        \n","        # dec_tokens embedding lookup\n","        dec_hidden = self.embedding(dec_tokens) + self.position(dec_tokens)\n","        dec_hidden = self.dropout(dec_hidden)\n","\n","        # call decoder layers\n","        for decoder_layer in self.decoder_layers:\n","            dec_hidden = decoder_layer((dec_hidden, enc_hidden, dec_self_mask, enc_dec_mask))\n","\n","        # call weight shared embedding (model=linear)\n","        logits = self.embedding(dec_hidden, mode='linear')\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MW2cNlE3d_8e"},"source":["def build_model(args):\n","    \"\"\"\n","    Transformer Model\n","    :param args: Args 객체\n","    \"\"\"\n","    enc_inputs = tf.keras.layers.Input((None,))  # (bs, ?)\n","    dec_inputs = tf.keras.layers.Input((None,))  # (bs, ?)\n","\n","    transformer = Transformer(args)\n","    logits = transformer((enc_inputs, dec_inputs))\n","    y_pred = tf.keras.layers.Softmax(name=\"lm\")(logits)\n","\n","    model = tf.keras.Model(inputs=(enc_inputs, dec_inputs), outputs=y_pred)\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"097BJVHG_QfR"},"source":["# Data*"]},{"cell_type":"code","metadata":{"id":"BvBz82afgule"},"source":["# 파일 다운로드 및 목록 확인\n","!wget https://github.com/songys/Chatbot_data/raw/master/ChatbotData.csv\n","os.listdir('./')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WB0cfrHoGOKX"},"source":["# Loss & Acc*"]},{"cell_type":"code","metadata":{"id":"ao1Ukq5MGabJ"},"source":["def lm_loss(y_true, y_pred):\n","    \"\"\"\n","    pad 부분을 제외하고 loss를 계산하는 함수\n","    :param y_true: 정답\n","    :param y_pred: 예측 값\n","    :retrun loss: pad 부분이 제외된 loss 값\n","    \"\"\"\n","    # loss 계산 (각각)\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n","    # 0이면 0, 아니면 1\n","    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","    # mask 부분을 0으로 변경\n","    loss *= mask\n","    # mask를 제외한 나머지 부분의 평균\n","    loss = tf.reduce_sum(loss) / tf.maximum(1., tf.reduce_sum(mask))\n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpCq4L65Gqs5"},"source":["def lm_acc(y_true, y_pred):\n","    \"\"\"\n","    pad 부분을 제외하고 accuracy를 계산하는 함수\n","    :param y_true: 정답\n","    :param y_pred: 예측 값\n","    :retrun loss: pad 부분이 제외된 accuracy 값\n","    \"\"\"\n","    y_true = tf.cast(y_true, tf.float32)\n","    # 예측 class\n","    y_class = tf.cast(tf.argmax(y_pred, axis=-1), tf.float32)\n","    # 예측값과 정답 비교\n","    matches = tf.cast(tf.equal(y_true, y_class), tf.float32)\n","    # 0이면 0, 아니면 1\n","    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","    # mask 부분을 0으로 변경\n","    matches *= mask\n","    # mask를 제외한 나머지 부분의 accuracy\n","    accuracy = tf.reduce_sum(matches) / tf.maximum(1., tf.reduce_sum(mask))\n","    return accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"auGUODYIiSxK"},"source":["# Scheduler*"]},{"cell_type":"code","metadata":{"id":"53eYgvRNiSdq"},"source":["class InverseSquareRootSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    \"\"\"\n","    TransformerSchedule class\n","    \"\"\"\n","    def __init__(self, d_model, warmup_steps=4000):\n","        \"\"\"\n","        생성자\n","        :param d_model: 모델 hidden\n","        :param warmup_steps: warmup steps\n","        \"\"\"\n","        super().__init__()\n","\n","        self.d_model = tf.cast(d_model, tf.float32)\n","        self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n","\n","    def __call__(self, step_num):\n","        \"\"\"\n","        learning rate 계산\n","        :param step_num: 현재 step number\n","        :retrun: 계산된 learning rate\n","        \"\"\"\n","        # calculate arg1 step_num ** -0.5\n","        arg1 = tf.math.rsqrt(step_num)\n","        # calculate arg2 step_num * warmup_steps ** -1.5\n","        arg2 = step_num * (self.warmup_steps**-1.5)\n","        # calcualte arg (min arg1 vs arg2)\n","        arg = tf.math.minimum(arg1, arg2)\n","        # calcualte lr (d_model ** -0.5 * arg)\n","        lr = tf.math.rsqrt(self.d_model) * arg\n","        return lr"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ozw2a2JBigXC"},"source":["schedule = InverseSquareRootSchedule(args.d_model, warmup_steps=100)\n","schedule(float(10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtVjIb2mimTY"},"source":["# compute lr\n","test_schedule = InverseSquareRootSchedule(args.d_model, warmup_steps=100)\n","lrs = []\n","for step in range(1000):\n","    lrs.append(test_schedule(float(step)).numpy())\n","\n","# draw\n","plt.plot(lrs, 'r-', label='learning_rate')\n","plt.xlabel('Step')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w_ch3BI9EC05"},"source":["# 실습\n","- Transformer를 이용한 chatbot을 학습하세요."]},{"cell_type":"markdown","metadata":{"id":"Xv8wb2wgEC05"},"source":["## Train 데이터 생성"]},{"cell_type":"code","metadata":{"id":"JEmOCQUiEC06"},"source":["# data load\n","df_train = pd.read_csv('ChatbotData.csv')\n","df_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rElE7QP0EC06"},"source":["# null 제거\n","df_train = df_train.dropna()\n","df_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U7EuG-p4EC07"},"source":["# Q 길이\n","q_length = df_train[\"Q\"].astype(\"str\").apply(lambda x:len(vocab.encode_as_pieces(x)))\n","q_length.head(10), q_length.max()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"afZqZQRhEC07"},"source":["# A 길이\n","a_length = df_train[\"A\"].astype(\"str\").apply(lambda x:len(vocab.encode_as_pieces(x)))\n","a_length.head(10), a_length.max()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfzLzjDCEC08"},"source":["def make_data(df, vocab, n_enc_seq, n_dec_seq):\n","    \"\"\"\n","    chat 학습 데이터 생성\n","    :param df: data frame\n","    :param df: vocab\n","    :param n_enc_seq: number of encoder sequence\n","    :param n_dec_seq: number of decoder sequence\n","    :return enc_inputs: encoder input data\n","    :return dec_inputs: decoder input data\n","    :return dec_labels: decoder label data\n","    \"\"\"\n","    n_enc_max = n_enc_seq\n","    n_dec_max = n_dec_seq - 1  # [BOS] or [EOS]\n","    # inputa & labels\n","    enc_inputs = []\n","    dec_inputs = []\n","    dec_labels = []\n","    # 데이터 생성\n","    for i, row in tqdm(df.iterrows(), total=len(df)):\n","        Q = row['Q']\n","        A = row['A']\n","        # print(Q, '/', A)\n","        # tokenize\n","        tokens_q = vocab.encode_as_ids(Q)\n","        # print(len(tokens_q), ':', tokens_q)\n","        tokens_a = vocab.encode_as_ids(A)\n","        # print(len(tokens_a), ':', tokens_a)\n","        # 최대 길이로 자르기\n","        tokens_q = tokens_q[:n_enc_max]\n","        # print(len(tokens_q), ':', tokens_q)\n","        tokens_a = tokens_a[:n_dec_max]\n","        # print(len(tokens_a), ':', tokens_a)\n","        # input & label 정의\n","        enc_input = tokens_q\n","        # print(len(enc_input), ':', enc_input)\n","        dec_input = [vocab.bos_id()] + tokens_a\n","        # print(len(dec_input), ':', dec_input)\n","        dec_label = tokens_a + [vocab.eos_id()]\n","        # print(len(dec_label), ':', dec_label)\n","        # pad 추가\n","        enc_input += [0] * (n_enc_seq - len(enc_input))\n","        # print(len(enc_input), ':', enc_input)\n","        dec_input += [0] * (n_dec_seq - len(dec_input))\n","        # print(len(dec_input), ':', dec_input)\n","        dec_label += [0] * (n_dec_seq - len(dec_label))\n","        # print(len(dec_label), ':', dec_label)\n","        # 값 저장\n","        enc_inputs.append(enc_input)\n","        dec_inputs.append(dec_input)\n","        dec_labels.append(dec_label)\n","    # to numpy array\n","    enc_inputs = np.array(enc_inputs)\n","    dec_inputs = np.array(dec_inputs)\n","    dec_labels = np.array(dec_labels)\n","    return enc_inputs, dec_inputs, dec_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QlYKvQUjEC08"},"source":["train_enc_inputs, train_dec_inputs, train_dec_labels = make_data(df_train, vocab, 27, 40)\n","train_enc_inputs, train_dec_inputs, train_dec_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q9TJovagEC08"},"source":["## Modeling"]},{"cell_type":"code","metadata":{"id":"Gx3NzXUoEC0-"},"source":["model = build_model(args)\n","tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tXRCzp0EC0-"},"source":["model.predict((train_enc_inputs[:4], train_dec_inputs[:4]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j3pUWwz0EC0_"},"source":["## Train"]},{"cell_type":"code","metadata":{"id":"3Bug3D6kEC0_"},"source":["model = build_model(args)\n","tf.keras.utils.plot_model(model, 'model.png', show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6baiThSmsMY"},"source":["learning_rate = InverseSquareRootSchedule(args.d_model, warmup_steps=1000)\n","optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a-1MKIIDEC0_"},"source":["model.compile(loss=lm_loss, optimizer=optimizer, metrics=[lm_acc])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kl22OLVJEC0_"},"source":["early_stopping = tf.keras.callbacks.EarlyStopping(monitor='lm_acc', patience=30)\n","save_weights = tf.keras.callbacks.ModelCheckpoint(os.path.join(sychat_dir, \"transformer.hdf5\"),\n","                                                  monitor='lm_acc',\n","                                                  verbose=1,\n","                                                  save_best_only=True,\n","                                                  mode=\"max\",\n","                                                  save_freq=\"epoch\",\n","                                                  save_weights_only=True)\n","csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(sychat_dir, \"transformer.csv\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SJlGRJmhEC0_"},"source":["history = model.fit((train_enc_inputs, train_dec_inputs),\n","                    train_dec_labels,\n","                    epochs=100,\n","                    batch_size=256,\n","                    callbacks=[early_stopping, save_weights, csv_logger])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSIHos9GEC0_"},"source":["plt.figure(figsize=(12, 4))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['loss'], 'b-', label='loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['lm_acc'], 'g-', label='accuracy')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMoKqFvLEC1A"},"source":["## BLEU"]},{"cell_type":"code","metadata":{"id":"zgMUesK4EC1A"},"source":["import nltk.translate.bleu_score as bleu\n","from nltk import ngrams"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x83Kl8yPEC1B"},"source":["## 평가"]},{"cell_type":"code","metadata":{"id":"5dIjXrXoEC1B"},"source":["model = build_model(args)\n","model.load_weights(os.path.join(sychat_dir, \"transformer.hdf5\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XMCPHTqfEC1C"},"source":["model.compile(loss=lm_loss, optimizer=optimizer, metrics=[lm_acc])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DTV6Qmh8EC1C"},"source":["# 100개만 확인\n","valid_enc_inputs = train_enc_inputs[:100]\n","valid_dec_inputs = train_dec_inputs[:100]\n","valid_dec_labels = train_dec_labels[:100]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gPrE6FngEC1D"},"source":["# 평가\n","model.evaluate((valid_enc_inputs, valid_dec_inputs), valid_dec_labels, batch_size=128)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M5a2hly_EC1D"},"source":["references = []\n","for row in valid_dec_labels:\n","    ids = []\n","    for i in row:\n","        if i == vocab.eos_id():\n","            break\n","        ids.append(int(i))\n","    string = vocab.id_to_piece(ids)\n","    references.append(string)\n","references"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mmQf6zEpEC1D"},"source":["# 예측\n","y_pred = model.predict((valid_enc_inputs, valid_dec_inputs))\n","y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orKtftWeEC1D"},"source":["# greedy decoding\n","y_pred_class = tf.argmax(y_pred, axis=-1).numpy()\n","y_pred_class"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8P4G0HorEC1D"},"source":["candidates = []\n","for row in y_pred_class:\n","    ids = []\n","    for i in row:\n","        if i == vocab.eos_id():\n","            break\n","        ids.append(int(i))\n","    string = vocab.id_to_piece(ids)\n","    candidates.append(string)\n","candidates"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":240},"id":"4ppKgAprEC1E","executionInfo":{"status":"error","timestamp":1647860249729,"user_tz":-540,"elapsed":329,"user":{"displayName":"현청천","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GingwsOzB_fFlwKa3Z4CH1TlVnyWMq-xfwt25iMhS0=s64","userId":"02662570985009482782"}},"outputId":"5bd6865f-61ab-40ab-f75c-539ee16e84e4"},"source":["bleu_scores = []\n","for reference, candidate in zip(references, candidates):\n","    bleu_score = bleu.sentence_bleu([reference], candidate)\n","    bleu_scores.append(bleu_score)\n","    print(bleu_score, \":\", reference, \"/\", candidate)\n","np.mean(bleu_scores)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0231cffd8394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbleu_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbleu_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbleu_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\":\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'references' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"MWob-9sOEC1E"},"source":["## 배포"]},{"cell_type":"code","metadata":{"id":"uVEoNdQqEC1E"},"source":["model = build_model(args)\n","model.load_weights(os.path.join(sychat_dir, \"transformer.hdf5\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yKs49rOEC1E"},"source":["def do_chat(vocab, model, n_dec_seq, string):\n","    \"\"\"\n","    seq2seq chat\n","    :param vocab: vocab\n","    :param model: model\n","    :param n_dec_seq: number of dec seqence\n","    :param string: inpust string\n","    \"\"\"\n","    # qeustion\n","    q_id = vocab.encode_as_ids(string)\n","\n","    # answer\n","    a_id = [vocab.bos_id()]\n","\n","    # 처음부터 예측\n","    start_idx = 0\n","\n","    for _ in range(start_idx, n_dec_seq - 1):\n","        # print(q_id)\n","        # print(a_id)\n","        outputs = model.predict((np.array([q_id]), np.array([a_id])))\n","        prob = outputs[0][start_idx]\n","        word_id = int(np.argmax(prob))\n","        # print(word_id)\n","        if word_id == vocab.eos_id():\n","            break\n","        a_id.append(word_id)\n","        start_idx += 1\n","    predict_id = a_id[1:start_idx + 1]\n","    # print(predict_id)\n","    predict_str = vocab.decode_ids(predict_id)\n","    return predict_str"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MA2cow0_EC1E"},"source":["string = '남에게 피해주지 않는 건 기본이죠.'\n","do_chat(vocab, model, 40, string)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l0clPQylEC1E"},"source":["while True:\n","    string = input('질문 > ')\n","    string = string.strip()\n","    if len(string) == 0:\n","        break\n","    predict_str = do_chat(vocab, model, 40, string)\n","    print(f'답변 > {predict_str}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H_OC7zJDLkGh"},"source":[""],"execution_count":null,"outputs":[]}]}